{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f5270fe-3a17-43ce-8f19-4c646c0f81d5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Reader & Writer\n",
    "##### Objectives\n",
    "1. Read from CSV files\n",
    "1. Read from JSON files\n",
    "1. Write DataFrame to files\n",
    "1. Write DataFrame to tables\n",
    "1. Write DataFrame to a Delta table\n",
    "\n",
    "##### Methods\n",
    "- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#input-and-output\" target=\"_blank\">DataFrameReader</a>: `csv`, `json`, `option`, `schema`\n",
    "- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#input-and-output\" target=\"_blank\">DataFrameWriter</a>: `mode`, `option`, `parquet`, `format`, `saveAsTable`\n",
    "- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html#pyspark.sql.types.StructType\" target=\"_blank\">StructType</a>: `toDDL`\n",
    "\n",
    "##### Spark Types\n",
    "- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#data-types\" target=\"_blank\">Types</a>: `ArrayType`, `DoubleType`, `IntegerType`, `LongType`, `StringType`, `StructType`, `StructField`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "679431bc-1721-483a-9a3a-f1262f42c04c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "",
       "datasetInfos": [],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finished setting up utiltity methods..."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "Finished setting up utiltity methods...",
       "datasetInfos": [],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Datasets mounted and student environment set up"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "Datasets mounted and student environment set up",
       "datasetInfos": [],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ./Includes/Classroom-Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b80a67b-f6a4-4b1d-8293-04ad41425b94",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## DataFrameReader\n",
    "Interface used to load a DataFrame from external storage systems\n",
    "\n",
    "```\n",
    "spark.read.parquet(\"path/to/files\")\n",
    "```\n",
    "\n",
    "DataFrameReader is accessible through the SparkSession attribute `read`. This class includes methods to load DataFrames from different external storage systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27a0bf06-f52d-4c32-812f-9cf3cfd27def",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Read from CSV files\n",
    "Read from CSV with the DataFrameReader's `csv` method and the following options:\n",
    "\n",
    "Tab separator, use first line as header, infer schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d7c2805-0e09-4558-8c17-609a34a12166",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "usersCsvPath = \"/mnt/training/ecommerce/users/users-500k.csv\"\n",
    "\n",
    "usersDF = (spark\n",
    "           .read\n",
    "           .option(\"sep\", \"\\t\")\n",
    "           .option(\"header\", True)\n",
    "           .option(\"inferSchema\", True)\n",
    "           .csv(usersCsvPath)\n",
    "          )\n",
    "\n",
    "usersDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f50e4fad-17d7-470f-b5e1-e028e9af09c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "path = \"/mnt/training/ecommerce/users/users-500k.csv\"\n",
    "\n",
    "usersDF = (spark.read\n",
    "                .format(\"csv\")\n",
    "                .option(\"sep\", \"\\t\")\n",
    "                .option(\"inferSchema\", True)\n",
    "                .option(\"header\", True)\n",
    "                .load(path)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dfc14687-ee8e-461d-9131-3eefd2319c78",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>user_id</th><th>user_first_touch_timestamp</th><th>email</th></tr></thead><tbody><tr><td>UA000000102357305</td><td>1592182691348767</td><td>null</td></tr><tr><td>UA000000102357308</td><td>1592183287634953</td><td>null</td></tr><tr><td>UA000000102357309</td><td>1592183302736627</td><td>null</td></tr><tr><td>UA000000102357321</td><td>1592184604178702</td><td>david23@orozco-parker.com</td></tr><tr><td>UA000000102357325</td><td>1592185154063628</td><td>null</td></tr><tr><td>UA000000102357335</td><td>1592186122660210</td><td>null</td></tr><tr><td>UA000000102357338</td><td>1592186300091435</td><td>null</td></tr><tr><td>UA000000102357348</td><td>1592187663145345</td><td>phillipmorgan@hotmail.com</td></tr><tr><td>UA000000102357350</td><td>1592187732257656</td><td>null</td></tr><tr><td>UA000000102357356</td><td>1592188311375015</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "UA000000102357305",
         1592182691348767,
         null
        ],
        [
         "UA000000102357308",
         1592183287634953,
         null
        ],
        [
         "UA000000102357309",
         1592183302736627,
         null
        ],
        [
         "UA000000102357321",
         1592184604178702,
         "david23@orozco-parker.com"
        ],
        [
         "UA000000102357325",
         1592185154063628,
         null
        ],
        [
         "UA000000102357335",
         1592186122660210,
         null
        ],
        [
         "UA000000102357338",
         1592186300091435,
         null
        ],
        [
         "UA000000102357348",
         1592187663145345,
         "phillipmorgan@hotmail.com"
        ],
        [
         "UA000000102357350",
         1592187732257656,
         null
        ],
        [
         "UA000000102357356",
         1592188311375015,
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "user_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "user_first_touch_timestamp",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "email",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(usersDF.limit(10).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e53f1add-b609-40fc-a427-3c5c48a1148d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Spark's Python API also allows you to specify the DataFrameReader options as parameters to the `csv` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b6ed3f1-8945-4fbc-86e4-887f46d9a196",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "usersDF = (spark\n",
    "           .read\n",
    "           .csv(usersCsvPath, sep=\"\\t\", header=True, inferSchema=True)\n",
    "          )\n",
    "\n",
    "usersDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d9df7d6-fe49-4116-ada8-77250a0e13fc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "root\n",
       " |-- user_id: string (nullable = true)\n",
       " |-- user_first_touch_timestamp: long (nullable = true)\n",
       " |-- email: string (nullable = true)\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "root\n |-- user_id: string (nullable = true)\n |-- user_first_touch_timestamp: long (nullable = true)\n |-- email: string (nullable = true)\n\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "usersDF = (spark.read.csv(path, sep=\"\\t\", header=True, inferSchema=True))\n",
    "\n",
    "usersDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c220657-0789-4a8a-95dd-a0534627d772",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Manually define the schema by creating a `StructType` with column names and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ddddcd65-6834-40cc-b7ea-7fa4f7eb97d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import LongType, StringType, StructType, StructField\n",
    "\n",
    "userDefinedSchema = StructType([\n",
    "    StructField(\"user_id\", StringType(), True),\n",
    "    StructField(\"user_first_touch_timestamp\", LongType(), True),\n",
    "    StructField(\"email\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93a45648-5cb1-4380-a9da-4c3ac013b0cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import LongType, StringType, StructType, StructField\n",
    "\n",
    "userDefinedSchema = StructType([\n",
    "                StructField(\"user_id\", StringType(), True),\n",
    "                StructField(\"user_first_touch_timestamp\", LongType(), True),\n",
    "                StructField(\"email\", StringType(), True)\n",
    "                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4692f5c4-9c9e-41bb-8c6e-a45a96114001",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Read from CSV using this user-defined schema instead of inferring the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c178102-5a1f-4951-aa40-e92e418ce2ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "usersDF = (spark\n",
    "           .read\n",
    "           .option(\"sep\", \"\\t\")\n",
    "           .option(\"header\", True)\n",
    "           .schema(userDefinedSchema)\n",
    "           .csv(path)\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a4fc14f-48e4-4522-8089-2f1019cfba79",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Alternatively, define the schema using <a href=\"https://en.wikipedia.org/wiki/Data_definition_language\" target=\"_blank\">data definition language (DDL)</a> syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9480bb73-39ce-4a1b-a1a5-6e35d05b08f7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DDLSchema = \"user_id string, user_first_touch_timestamp long, email string\"\n",
    "\n",
    "usersDF = (spark\n",
    "           .read\n",
    "           .option(\"sep\", \"\\t\")\n",
    "           .option(\"header\", True)\n",
    "           .schema(DDLSchema)\n",
    "           .csv(path)\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "010057d9-6a6b-4dbc-af2b-4423cf375d31",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Read from JSON files\n",
    "\n",
    "Read from JSON with DataFrameReader's `json` method and the infer schema option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24f75fb6-2713-4f38-93d5-9d58b5baba0c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "eventsJsonPath = \"/mnt/training/ecommerce/events/events-500k.json\"\n",
    "\n",
    "eventsDF = (spark\n",
    "            .read\n",
    "            .option(\"inferSchema\", True)\n",
    "            .json(eventsJsonPath)\n",
    "           )\n",
    "\n",
    "eventsDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6a85833-2d56-48da-bd4e-39831a89c76a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "json_path = \"/mnt/training/ecommerce/events/events-500k.json\"\n",
    "\n",
    "eventsDF = (spark.read\n",
    "                .format(\"json\")\n",
    "                .option(\"inferSchema\", True)\n",
    "                .load(json_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c158ca86-eb1b-4101-a406-7cb171c55d2a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "root\n",
       " |-- device: string (nullable = true)\n",
       " |-- ecommerce: struct (nullable = true)\n",
       " |    |-- purchase_revenue_in_usd: double (nullable = true)\n",
       " |    |-- total_item_quantity: long (nullable = true)\n",
       " |    |-- unique_items: long (nullable = true)\n",
       " |-- event_name: string (nullable = true)\n",
       " |-- event_previous_timestamp: long (nullable = true)\n",
       " |-- event_timestamp: long (nullable = true)\n",
       " |-- geo: struct (nullable = true)\n",
       " |    |-- city: string (nullable = true)\n",
       " |    |-- state: string (nullable = true)\n",
       " |-- items: array (nullable = true)\n",
       " |    |-- element: struct (containsNull = true)\n",
       " |    |    |-- coupon: string (nullable = true)\n",
       " |    |    |-- item_id: string (nullable = true)\n",
       " |    |    |-- item_name: string (nullable = true)\n",
       " |    |    |-- item_revenue_in_usd: double (nullable = true)\n",
       " |    |    |-- price_in_usd: double (nullable = true)\n",
       " |    |    |-- quantity: long (nullable = true)\n",
       " |-- traffic_source: string (nullable = true)\n",
       " |-- user_first_touch_timestamp: long (nullable = true)\n",
       " |-- user_id: string (nullable = true)\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "root\n |-- device: string (nullable = true)\n |-- ecommerce: struct (nullable = true)\n |    |-- purchase_revenue_in_usd: double (nullable = true)\n |    |-- total_item_quantity: long (nullable = true)\n |    |-- unique_items: long (nullable = true)\n |-- event_name: string (nullable = true)\n |-- event_previous_timestamp: long (nullable = true)\n |-- event_timestamp: long (nullable = true)\n |-- geo: struct (nullable = true)\n |    |-- city: string (nullable = true)\n |    |-- state: string (nullable = true)\n |-- items: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- coupon: string (nullable = true)\n |    |    |-- item_id: string (nullable = true)\n |    |    |-- item_name: string (nullable = true)\n |    |    |-- item_revenue_in_usd: double (nullable = true)\n |    |    |-- price_in_usd: double (nullable = true)\n |    |    |-- quantity: long (nullable = true)\n |-- traffic_source: string (nullable = true)\n |-- user_first_touch_timestamp: long (nullable = true)\n |-- user_id: string (nullable = true)\n\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eventsDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8cd12502-592a-4e51-acce-6e5e6116e5c4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Read data faster by creating a `StructType` with the schema names and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f6e6af1-ed54-4646-bda1-ea1d352bfa31",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ArrayType, DoubleType, IntegerType, LongType, StringType, StructType, StructField\n",
    "\n",
    "userDefinedSchema = StructType([\n",
    "    StructField(\"device\", StringType(), True),\n",
    "    StructField(\"ecommerce\", StructType([\n",
    "        StructField(\"purchaseRevenue\", DoubleType(), True),\n",
    "        StructField(\"total_item_quantity\", LongType(), True),\n",
    "        StructField(\"unique_items\", LongType(), True)\n",
    "    ]), True),\n",
    "    StructField(\"event_name\", StringType(), True),\n",
    "    StructField(\"event_previous_timestamp\", LongType(), True),\n",
    "    StructField(\"event_timestamp\", LongType(), True),\n",
    "    StructField(\"geo\", StructType([\n",
    "        StructField(\"city\", StringType(), True),\n",
    "        StructField(\"state\", StringType(), True)\n",
    "    ]), True),\n",
    "    StructField(\"items\", ArrayType(\n",
    "        StructType([\n",
    "            StructField(\"coupon\", StringType(), True),\n",
    "            StructField(\"item_id\", StringType(), True),\n",
    "            StructField(\"item_name\", StringType(), True),\n",
    "            StructField(\"item_revenue_in_usd\", DoubleType(), True),\n",
    "            StructField(\"price_in_usd\", DoubleType(), True),\n",
    "            StructField(\"quantity\", LongType(), True)\n",
    "        ])\n",
    "    ), True),\n",
    "    StructField(\"traffic_source\", StringType(), True),\n",
    "    StructField(\"user_first_touch_timestamp\", LongType(), True),\n",
    "    StructField(\"user_id\", StringType(), True)\n",
    "])\n",
    "\n",
    "eventsDF = (spark\n",
    "            .read\n",
    "            .schema(userDefinedSchema)\n",
    "            .json(json_path)\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7c185d5-53f7-4b7f-9667-6541aacec959",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "You can use the `StructType` Scala method `toDDL` to have a DDL-formatted string created for you.\n",
    "\n",
    "In a Python notebook, create a Scala cell to create the string to copy and paste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "578ccad1-1725-40fa-9363-bc24eea7551b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">res3: String = device STRING,ecommerce STRUCT&lt;purchase_revenue_in_usd: DOUBLE, total_item_quantity: BIGINT, unique_items: BIGINT&gt;,event_name STRING,event_previous_timestamp BIGINT,event_timestamp BIGINT,geo STRUCT&lt;city: STRING, state: STRING&gt;,items ARRAY&lt;STRUCT&lt;coupon: STRING, item_id: STRING, item_name: STRING, item_revenue_in_usd: DOUBLE, price_in_usd: DOUBLE, quantity: BIGINT&gt;&gt;,traffic_source STRING,user_first_touch_timestamp BIGINT,user_id STRING\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">res3: String = device STRING,ecommerce STRUCT&lt;purchase_revenue_in_usd: DOUBLE, total_item_quantity: BIGINT, unique_items: BIGINT&gt;,event_name STRING,event_previous_timestamp BIGINT,event_timestamp BIGINT,geo STRUCT&lt;city: STRING, state: STRING&gt;,items ARRAY&lt;STRUCT&lt;coupon: STRING, item_id: STRING, item_name: STRING, item_revenue_in_usd: DOUBLE, price_in_usd: DOUBLE, quantity: BIGINT&gt;&gt;,traffic_source STRING,user_first_touch_timestamp BIGINT,user_id STRING\n</div>",
       "datasetInfos": [],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%scala\n",
    "spark.read.parquet(\"/mnt/training/ecommerce/events/events.parquet\").schema.toDDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9eaaa7b9-133e-42bc-9eec-1fffab91e897",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DDLSchema = \"`device` STRING,`ecommerce` STRUCT<`purchase_revenue_in_usd`: DOUBLE, `total_item_quantity`: BIGINT, `unique_items`: BIGINT>,`event_name` STRING,`event_previous_timestamp` BIGINT,`event_timestamp` BIGINT,`geo` STRUCT<`city`: STRING, `state`: STRING>,`items` ARRAY<STRUCT<`coupon`: STRING, `item_id`: STRING, `item_name`: STRING, `item_revenue_in_usd`: DOUBLE, `price_in_usd`: DOUBLE, `quantity`: BIGINT>>,`traffic_source` STRING,`user_first_touch_timestamp` BIGINT,`user_id` STRING\"\n",
    "\n",
    "eventsDF = (spark\n",
    "            .read\n",
    "            .schema(DDLSchema)\n",
    "            .json(json_path)\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "723e02a2-48e0-453a-8d61-0f415efb9e58",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## DataFrameWriter\n",
    "Interface used to write a DataFrame to external storage systems\n",
    "\n",
    "```\n",
    "(df.write                         \n",
    "  .option(\"compression\", \"snappy\")\n",
    "  .mode(\"overwrite\")      \n",
    "  .parquet(outPath)       \n",
    ")\n",
    "```\n",
    "\n",
    "DataFrameWriter is accessible through the SparkSession attribute `write`. This class includes methods to write DataFrames to different external storage systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2206712d-ec0b-4d75-aaf4-2ee91b8e65d4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Write DataFrames to files\n",
    "\n",
    "Write `usersDF` to parquet with DataFrameWriter's `parquet` method and the following configurations:\n",
    "\n",
    "Snappy compression, overwrite mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c97bd187-5cfc-4928-9390-84ca62e07529",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "usersOutputPath = workingDir + \"/users.parquet\"\n",
    "\n",
    "(usersDF\n",
    " .write\n",
    " .option(\"compression\", \"snappy\")\n",
    " .mode(\"overwrite\")\n",
    " .parquet(usersOutputPath)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "513657f0-7a1e-4d91-ab65-eb5800cf3ab1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(\n",
    "    dbutils.fs.ls(usersOutputPath)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06a67ff8-f6d8-43fb-b90f-77fa589a2d6e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "As with DataFrameReader, Spark's Python API also allows you to specify the DataFrameWriter options as parameters to the `parquet` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27d1af41-d10c-4978-8777-0eb575a17f7e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(usersDF\n",
    " .write\n",
    " .parquet(usersOutputPath, compression=\"snappy\", mode=\"overwrite\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "405f864d-b10c-4fa9-bbbc-204aa0d0a1c0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Write DataFrames to tables\n",
    "\n",
    "Write `eventsDF` to a table using the DataFrameWriter method `saveAsTable`\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/icon_note_32.png\" alt=\"Note\"> This creates a global table, unlike the local view created by the DataFrame method `createOrReplaceTempView`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b9a6c1b-89b6-446a-a452-3b4f44afee60",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "eventsDF.write.mode(\"overwrite\").saveAsTable(\"events_p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81bf9109-af1b-42ca-8b92-6f6883f6ae85",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This table was saved in the database created for you in classroom setup. See database name printed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4df70cea-3463-491c-8fb9-a4fa43ce8a85",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(databaseName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8bc6b06-8d55-42dd-9f1b-e8063bf8102a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Delta Lake\n",
    "\n",
    "In almost all cases, the best practice is to use Delta Lake format, especially whenever the data will be referenced from a Databricks workspace. \n",
    "\n",
    "<a href=\"https://delta.io/\" target=\"_blank\">Delta Lake</a> is an open source technology designed to work with Spark to bring reliability to data lakes.\n",
    "\n",
    "![delta](https://files.training.databricks.com/images/aspwd/delta_storage_layer.png)\n",
    "\n",
    "#### Delta Lake's Key Features\n",
    "- ACID transactions\n",
    "- Scalable metadata handline\n",
    "- Unified streaming and batch processing\n",
    "- Time travel (data versioning)\n",
    "- Schema enforcement and evolution\n",
    "- Audit history\n",
    "- Parquet format\n",
    "- Compatible with Apache Spark API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "737bac08-89f6-4f81-b8a2-c51a779d843a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Write Results to a Delta Table\n",
    "\n",
    "Write `eventsDF` with the DataFrameWriter's `save` method and the following configurations: Delta format, overwrite mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd6ed12d-5dff-4c44-893b-c52568fd2fc9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "eventsOutputPath = workingDir + \"/delta/events\"\n",
    "\n",
    "(eventsDF\n",
    " .write\n",
    " .format(\"delta\")\n",
    " .mode(\"overwrite\")\n",
    " .save(eventsOutputPath)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f9c31f4-5bd3-4ef7-ad78-203c3acd873e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Ingesting Data Lab\n",
    "\n",
    "Read in CSV files containing products data.\n",
    "\n",
    "##### Tasks\n",
    "1. Read with infer schema\n",
    "2. Read with user-defined schema\n",
    "3. Read with schema as DDL formatted string\n",
    "4. Write using Delta format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "288e6c7e-1ad1-4db5-89d0-cfb06040c87c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Read with infer schema\n",
    "- View the first CSV file using DBUtils method `fs.head` with the filepath provided in the variable `singleProductCsvFilePath`\n",
    "- Create `productsDF` by reading from CSV files located in the filepath provided in the variable `productsCsvPath`\n",
    "  - Configure options to use first line as header and infer schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "387388e5-68ef-492b-8d08-516508b0c1e3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id,name,price\n",
       "M_PREM_Q,Premium Queen Mattress,1795.0\n",
       "M_STAN_F,Standard Full Mattress,945.0\n",
       "M_PREM_F,Premium Full Mattress,1695.0\n",
       "\n",
       "root\n",
       " |-- item_id: string (nullable = true)\n",
       " |-- name: string (nullable = true)\n",
       " |-- price: double (nullable = true)\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "item_id,name,price\nM_PREM_Q,Premium Queen Mattress,1795.0\nM_STAN_F,Standard Full Mattress,945.0\nM_PREM_F,Premium Full Mattress,1695.0\n\nroot\n |-- item_id: string (nullable = true)\n |-- name: string (nullable = true)\n |-- price: double (nullable = true)\n\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO\n",
    "singleProductCsvFilePath = \"/mnt/training/ecommerce/products/products.csv/part-00000-tid-1663954264736839188-daf30e86-5967-4173-b9ae-d1481d3506db-2367-1-c000.csv\"\n",
    "\n",
    "print(dbutils.fs.head(singleProductCsvFilePath))\n",
    "\n",
    "productsCsvPath = \"/mnt/training/ecommerce/products/products.csv\"\n",
    "\n",
    "productsDF  = (spark.read\n",
    "                    .option(\"header\", True)\n",
    "                    .option(\"inferSchema\", True)\n",
    "                    .csv(productsCsvPath))\n",
    "\n",
    "productsDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a13d3d6-7431-400d-b359-9b74a3fd6602",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**CHECK YOUR WORK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1293d2e7-26a1-4e89-956a-d7b4a671da45",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "assert(productsDF.count() == 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9aea18b8-3255-44cb-b32a-117949605eab",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2. Read with user-defined schema\n",
    "Define schema by creating a `StructType` with column names and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31d02549-fc14-4114-a5eb-1fb290d23e3c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "userDefinedSchema = StructType([\n",
    "                      StructField(\"item_id\", StringType(), True),\n",
    "                      StructField(\"name\", StringType(), True),\n",
    "                      StructField(\"price\", DoubleType(), True)\n",
    "                      ])\n",
    "\n",
    "productsDF2 = (spark.read\n",
    "                   .option(\"header\", True)\n",
    "                   .schema(userDefinedSchema)\n",
    "                   .csv(productsCsvPath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3172b93d-14cc-4a5e-9e95-3e6b6fb0d43d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**CHECK YOUR WORK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b2ca039-f628-4066-beec-42a2b55fc3b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "assert(userDefinedSchema.fieldNames() == [\"item_id\", \"name\", \"price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b18c4ddc-a81b-4e13-b063-090eaa70ee20",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "expected1 = Row(item_id=\"M_STAN_Q\", name=\"Standard Queen Mattress\", price=1045.0)\n",
    "result1 = productsDF2.first()\n",
    "\n",
    "assert(expected1 == result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10c8ed42-b64f-4b33-9e3f-f04a8158f9e7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3. Read with DDL formatted string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07ce31da-508f-4b62-88fa-a7870a61150c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "DDLSchema = \"`item_id` STRING, `name` STRING, `price` DOUBLE\"\n",
    "\n",
    "productsDF3 = (spark.read\n",
    "                    .option(\"header\", True)\n",
    "                    .schema(DDLSchema)\n",
    "                    .csv(productsCsvPath)\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c80ff38d-1f84-4acf-8f4e-2ebc015ad0ac",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**CHECK YOUR WORK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce80b442-0571-4836-9f73-156ec890d1f7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "assert(productsDF3.count() == 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5420eacb-db65-46f0-ab10-6e1355e61ee2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4. Write to Delta\n",
    "Write `productsDF` to the filepath provided in the variable `productsOutputPath`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea603b15-8b94-412d-ad71-ba8c8acbda24",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "productsOutputPath = workingDir + \"/delta/products\"\n",
    "\n",
    "(productsDF.write\n",
    "          .format(\"delta\")\n",
    "          .mode(\"overwrite\")\n",
    "          .save(productsOutputPath)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1fb1c2a1-e6f1-4dc2-8f28-8fc2dcbc4ccd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**CHECK YOUR WORK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d5c0db8-46fb-4ac0-90b1-64e565eb94f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "verify_files = dbutils.fs.ls(productsOutputPath)\n",
    "verify_delta_format = False\n",
    "verify_num_data_files = 0\n",
    "for f in verify_files:\n",
    "    if f.name == '_delta_log/':\n",
    "        verify_delta_format = True\n",
    "    elif f.name.endswith('.parquet'):\n",
    "        verify_num_data_files += 1\n",
    "\n",
    "assert verify_delta_format, \"Data not written in Delta format\"\n",
    "assert verify_num_data_files > 0, \"No data written\"\n",
    "del verify_files, verify_delta_format, verify_num_data_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49f9c77d-751e-4a3c-bb32-b6fb1d696aca",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Clean up classroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77d455d6-fb9d-4b5e-9def-fe21eb4198cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Dropped database and removed files in working directory"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "Dropped database and removed files in working directory",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ./Includes/Classroom-Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "implicitDf": true
     },
     "inputWidgets": {},
     "nuid": "948962fd-7fca-4476-85de-ec0e713b586a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "\n",
    "DROP DATABASE dbacademy_admin_databricks_novigosolutions_com_spark_programming_asp_1_4___reader___writer CASCADE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce9f9a7d-dcbd-4a3f-915e-912c6a83bdb3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "-sandbox\n",
    "&copy; 2022 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "<br/>\n",
    "<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1200856915510601,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "ASP 1.4 - Reader & Writer",
   "notebookOrigID": 874905206501762,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
